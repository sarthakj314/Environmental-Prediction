{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from netCDF4 import Dataset\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from datetime import timedelta, date\n",
    "from s2cloudless import S2PixelCloudDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_path = open('path_to_data.txt').read()\n",
    "print(cwd, '\\n', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data directory\n",
    "data_directory = data_path\n",
    "DIR = sorted(os.listdir(data_directory))\n",
    "#DIR = [file for file in DIR if ('deforestation' in file)]\n",
    "DIR = [file for file in DIR if (('fire' not in file))]\n",
    "\n",
    "# Initialize an empty dictionary to store the file names and their data point counts\n",
    "data_counts = {}\n",
    "\n",
    "# Loop through each file in the data directory\n",
    "for filename in DIR:\n",
    "    if filename.endswith('.nc'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        \n",
    "        # Open the .nc file\n",
    "        with Dataset(file_path, 'r') as nc_file:\n",
    "            # Assuming the data variable is named 'data', adjust as necessary\n",
    "            data_variable = nc_file.variables['index']\n",
    "            \n",
    "            # Count the number of data points\n",
    "            num_data_points = data_variable.size\n",
    "            \n",
    "            # Store the count in the dictionary\n",
    "            data_counts[filename] = num_data_points\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(list(data_counts.items()), columns=['File Name', 'Number of Data Points'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NP Array Metadata Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_metadata(arr, name='Array', print_unique_values=False, print_unique_counts=False):\n",
    "    print()\n",
    "    print('Name:', name)\n",
    "    print('\\tShape:', arr.shape)\n",
    "    print('\\tSize:', arr.size)\n",
    "    print('\\tDimensions:', arr.ndim)\n",
    "    print('\\tDtype:', arr.dtype)\n",
    "    print('\\tMemory Usage:', arr.nbytes, 'bytes')\n",
    "    if '<U' not in str(arr.dtype):\n",
    "        print('\\tMIN:', arr.min())\n",
    "        print('\\tMAX:', arr.max())\n",
    "    if print_unique_values:\n",
    "        print('\\tNum Unique Values:', np.unique(arr).size)\n",
    "        if print_unique_counts:\n",
    "            print('\\tUnique Values:', np.unique(arr, return_counts=True))\n",
    "    print('\\tPreview:', arr[:10])\n",
    "    print()\n",
    "\n",
    "def np_metadata_image(image, name='Image', print_unique_values=False):\n",
    "    print()\n",
    "    print('Name:', name)\n",
    "    print('\\tShape:', image.shape)\n",
    "    print('\\tSize:', image.size)\n",
    "    print('\\tDimensions:', image.ndim)\n",
    "    print('\\tDtype:', image.dtype)\n",
    "    print('\\tMemory Usage:', image.nbytes, 'bytes')\n",
    "    print('\\tMIN:', image.min())\n",
    "    print('\\tMAX:', image.max())\n",
    "    print('\\tNum Unique Values:', np.unique(image).size)\n",
    "    if print_unique_values:\n",
    "        print('\\tUnique Values:', np.unique(image))\n",
    "    '''\n",
    "    print('\\tPreview:')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    '''\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 'at-a-glance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### netCDF date interpreter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_from_date_delta(n, date='2018-12-13'):\n",
    "    date = pd.to_datetime(date)\n",
    "    return (date + timedelta(days=int(n))).strftime('%Y-%m-%d')\n",
    "\n",
    "def delta_from_date_date(date, date0='2018-12-13'):\n",
    "    date0 = pd.to_datetime(date0)\n",
    "    date = pd.to_datetime(date)\n",
    "    return (date - date0).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel-2 Deforestation Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2_deforestation_segmentation = Dataset(os.path.join(data_directory, 'sent2_deforestation_segmentation.nc'))\n",
    "print('SENTINEL-2 Deforestation Train:', nc_file.variables.keys())\n",
    "COORDS = np.array(sent2_deforestation_segmentation.variables['center_lat_lons']).T\n",
    "np_metadata(COORDS[0], 'Latitude')\n",
    "np_metadata(COORDS[1], 'Longitude')\n",
    "\n",
    "# Deforestation Test Set Collction Dates\n",
    "dates = sent2_deforestation_segmentation.variables['collection_dates']\n",
    "dates = np.array(dates[:])\n",
    "print('Collection dates:', dates, '\\tLength:', len(dates))\n",
    "value, counts = np.unique(dates, return_counts=True)\n",
    "Gregorian_dates = [date_from_date_delta(i) for i in value]\n",
    "print('Unique Collection Dates:', Gregorian_dates)\n",
    "print('Data Bands', np.array(sent2_deforestation_segmentation.variables['data_band']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinel-2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2_b1_b4_train = Dataset(os.path.join(data_directory, 'sent2_b1-b4_train.nc'))\n",
    "print('SENTINEL-2 B1-B4+QA60 Deforestation Train:', nc_file.variables.keys())\n",
    "print('Image Shape:', sent2_b1_b4_train.variables['images'].shape)\n",
    "COORDS = np.array(sent2_b1_b4_train.variables['center_lat_lons']).T\n",
    "np_metadata(COORDS[0], 'Latitude')\n",
    "np_metadata(COORDS[1], 'Longitude')\n",
    "DATA_BANDS_1_4 = np.array(sent2_b1_b4_train.variables['data_band'])\n",
    "np_metadata(DATA_BANDS_1_4, 'Data Bands')\n",
    "\n",
    "# Deforestation Test Set Collection Dates\n",
    "dates = sent2_b1_b4_train.variables['collection_dates']\n",
    "dates = np.array(dates[:])\n",
    "print('Collection dates:', dates, '\\tLength:', len(dates))\n",
    "value, counts = np.unique(dates, return_counts=True)\n",
    "Gregorian_dates = [date_from_date_delta(i) for i in value]\n",
    "print('Unique Collection Dates:', Gregorian_dates)\n",
    "np_metadata(counts, 'Unique Collection Dates Counts')\n",
    "\n",
    "'''\n",
    "sent2_b5_b8_train = Dataset(os.path.join(data_directory, 'sent2_b5-b8_train.nc'))\n",
    "print('SENTINEL-2 B5-B8A+QA60 Deforestation Train:', nc_file.variables.keys())\n",
    "DATA_BANDS_5_8 = np.array(sent2_b5_b8_train.variables['data_band'])\n",
    "np_metadata(DATA_BANDS_5_8, 'Data Bands')\n",
    "\n",
    "sent2_b9_b12_train = Dataset(os.path.join(data_directory, 'sent2_b9-b12_train.nc'))\n",
    "print('SENTINEL-2 B9-B12+QA60 Deforestation Train:', nc_file.variables.keys())\n",
    "DATA_BANDS_9_12 = np.array(sent2_b9_b12_train.variables['data_band'])\n",
    "np_metadata(DATA_BANDS_9_12, 'Data Bands')\n",
    "\n",
    "DATA_BANDS = np.concatenate((DATA_BANDS_1_4, DATA_BANDS_5_8[:-1], DATA_BANDS_9_12[:-1]), axis=0)\n",
    "DATA_BANDS_DICT = {DATA_BANDS[i] : i for i in range(DATA_BANDS.shape[0])}\n",
    "print('Data Bands:', DATA_BANDS)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Datasets\n",
    "- Coordinates\n",
    "- Dates\n",
    "- Data Bands\n",
    "- Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_sent2 = sent2_b1_b4_train\n",
    "Additional_sent2 = sent2_deforestation_segmentation\n",
    "\n",
    "# Coordinates\n",
    "Original_COORDS = np.array(Original_sent2.variables['center_lat_lons']).T\n",
    "Additional_COORDS = np.array(Additional_sent2.variables['center_lat_lons']).T\n",
    "COORDS = np.concatenate((Original_COORDS, Additional_COORDS), axis=1)\n",
    "np_metadata(COORDS, 'Coordinates')\n",
    "\n",
    "# Dates\n",
    "Original_DATES = np.array(Original_sent2.variables['collection_dates'])\n",
    "Additional_DATES = np.array(Additional_sent2.variables['collection_dates'])\n",
    "Combined_DATES_ARR = np.concatenate((Original_DATES, Additional_DATES), axis=0)\n",
    "DATES = []\n",
    "num_processes = mp.cpu_count()\n",
    "print('Number of Processes:', num_processes)\n",
    "pool = mp.Pool(processes=num_processes)\n",
    "args = [(str(NUM)) for NUM in Combined_DATES_ARR]\n",
    "partial_date_from_date_delta = partial(date_from_date_delta, date='2018-12-13')\n",
    "for outputs in tqdm(pool.imap(partial_date_from_date_delta, args), total=len(args)):\n",
    "    DATES.append(outputs)\n",
    "    pass\n",
    "pool.close()\n",
    "pool.join()\n",
    "DATES = np.array(DATES)\n",
    "np_metadata(DATES, 'Dates')\n",
    "\n",
    "# Data Bands\n",
    "Original_DATA_BANDS = np.array(Original_sent2.variables['data_band'])\n",
    "Additional_DATA_BANDS = np.array(Additional_sent2.variables['data_band'])\n",
    "Additional_DATA_BANDS_DICT = {Additional_DATA_BANDS[i] : i for i in range(Additional_DATA_BANDS.shape[0])}\n",
    "DATA_BANDS = Original_DATA_BANDS\n",
    "\n",
    "# Images\n",
    "def get_image(idx):\n",
    "    Original_num_images = Original_sent2.variables['images'].shape[0]\n",
    "    Additional_num_images = Additional_sent2.variables['images'].shape[0]\n",
    "    if idx < Original_num_images:\n",
    "        return np.array(Original_sent2.variables['images'][idx])\n",
    "    else:\n",
    "        idx -= Original_num_images\n",
    "        img = np.array(Additional_sent2.variables['images'][idx])\n",
    "        img = img[[Additional_DATA_BANDS_DICT[band] for band in DATA_BANDS]]\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Valid Data\n",
    "\n",
    "## Criterion:\n",
    "- CV2 algorithm is used to calculate the cloud coverage, and the threshold is set to <20%.\n",
    "- QA60 mask is used to filter out the cloudy pixels, and the threshold is set to <50%.\n",
    "- RGB mean of non-cloudy pixels evaluated from CV2 algorithm is used to filter out nighttime/low-light images, and the threshold is set to >0.1 (RGB range 0-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Detection Helper Functions\n",
    "- detect_clouds_qa60 - Calculates the cloud coverage given the QA60 band\n",
    "- cv2_cloud_mask - Calculates cloud mask given RGB image using CV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_clouds_qa60(qa60_band):\n",
    "    \"\"\"\n",
    "    Detects clouds in a QA60 band using bitmasks.\n",
    "    \n",
    "    Parameters:\n",
    "    qa60_band (numpy.ndarray): 2D NumPy array representing the QA60 band.\n",
    "    \n",
    "    Returns:\n",
    "    float: Percentage of the image covered by clouds.\n",
    "    \"\"\"\n",
    "    # Define the bitmasks for clouds and cirrus\n",
    "    cloud_bitmask = 1 << 10\n",
    "    cirrus_bitmask = 1 << 11\n",
    "    \n",
    "    # Apply the bitmasks to detect clouds and cirrus\n",
    "    cloud_mask = (qa60_band & cloud_bitmask) != 0\n",
    "    cirrus_mask = (qa60_band & cirrus_bitmask) != 0\n",
    "    \n",
    "    # Combine the masks\n",
    "    combined_mask = np.logical_or(cloud_mask, cirrus_mask)\n",
    "    \n",
    "    # Calculate the percentage of cloud cover\n",
    "    cloud_pixels = np.sum(combined_mask)\n",
    "    total_pixels = qa60_band.size\n",
    "    cloud_coverage = (cloud_pixels / total_pixels) * 100\n",
    "    \n",
    "    return cloud_coverage\n",
    "\n",
    "def cv2_cloud_mask(image):\n",
    "    \"\"\"\n",
    "    Detects clouds in a Sentinel-2 image using OpenCV.\n",
    "    \n",
    "    Parameters:\n",
    "    image (numpy.ndarray): 3D NumPy array representing the Sentinel-2 image with bands in the order [B2, B3, B4, B8, B8A, B11, B12].\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: 2D NumPy array representing the cloud mask.\n",
    "    \"\"\"\n",
    "    # Convert the image to 8-bit unsigned integer format\n",
    "    image_8bit = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert the image to the BGR color space\n",
    "    image_bgr = cv2.cvtColor(image_8bit, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Convert the image to the LAB color space\n",
    "    image_lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2Lab)\n",
    "    \n",
    "    # Split the LAB image into its components\n",
    "    L, A, B = cv2.split(image_lab)\n",
    "    \n",
    "    # Apply CLAHE to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    L_clahe = clahe.apply(L)\n",
    "    \n",
    "    # Merge the CLAHE-enhanced L channel with the original A and B channels\n",
    "    image_clahe = cv2.merge([L_clahe, A, B])\n",
    "    \n",
    "    # Convert the image back to the RGB color space\n",
    "    image_rgb_clahe = cv2.cvtColor(image_clahe, cv2.COLOR_Lab2RGB)\n",
    "    \n",
    "    # Convert the image to the HSV color space\n",
    "    image_hsv = cv2.cvtColor(image_rgb_clahe, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Threshold the image to get a binary mask of clouds\n",
    "    lower = np.array([0, 0, 0])\n",
    "    upper = np.array([180, 40, 255])\n",
    "    cloud_mask = cv2.inRange(image_hsv, lower, upper)\n",
    "    \n",
    "    return cloud_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate & Save\n",
    "- (i) QA60 Estimated Cloud Coverage \n",
    "- (ii) RGB Mean (CV2 Cloud Mask Removed) \n",
    "- (iii) CV2 Estimated Cloud Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2_meta = []\n",
    "if 'sent2_metadata.npy' in os.listdir(cwd):\n",
    "    sent2_meta = np.load('sent2_metadata.npy', allow_pickle=True).tolist()\n",
    "    print('Loaded sent2_meta:', len(sent2_meta))\n",
    "\n",
    "def cloud_coverage(i):\n",
    "    image = get_image(i)[1:4][::-1].squeeze().transpose(1, 2, 0)\n",
    "\n",
    "    # clip bottom and top 5% of pixel values to remove outliers and normalize\n",
    "    percentile = np.percentile(image, [5, 95])\n",
    "    image = np.clip(image, percentile[0], percentile[1])\n",
    "    image = (image - percentile[0]) / (percentile[1] - percentile[0])\n",
    "\n",
    "    cloud_mask_cv2 = cv2_cloud_mask(image)/255\n",
    "    cv2_cloud_percentage = np.sum(cloud_mask_cv2) / cloud_mask_cv2.size * 100\n",
    "\n",
    "    # find average pixel values excluding clouds\n",
    "    tmp = np.mean(image, axis=-1)\n",
    "    tmp = tmp - cloud_mask_cv2\n",
    "    tmp[tmp < 0] = 0\n",
    "    rgb_mean = tmp.sum() / np.sum(cloud_mask_cv2 == 0)\n",
    "    \n",
    "\n",
    "    mask = get_image(i)[4]\n",
    "    return (detect_clouds_qa60(mask), rgb_mean, cv2_cloud_percentage)\n",
    "\n",
    "num_processes = mp.cpu_count()\n",
    "print('Number of processes:', num_processes)\n",
    "pool = mp.Pool(processes=num_processes)\n",
    "args = [(i) for i in range(len(DATES)) if i >= len(sent2_meta)]\n",
    "\n",
    "for cloud in tqdm(pool.imap(cloud_coverage, args), total=len(args)):\n",
    "    sent2_meta.append(cloud)\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "print(len(args), len(sent2_meta))\n",
    "\n",
    "sent2_meta = np.array(sent2_meta)\n",
    "np_metadata(sent2_meta, 'Cloud Coverage')\n",
    "# save the cloud coverage list\n",
    "np.save('sent2_metadata.npy', sent2_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tolerance Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA60_tolerance = 50\n",
    "BRIGHTNESS_tolerance = 0.1\n",
    "CV2_CLOUD_tolerance = 20\n",
    "\n",
    "# Threshold CV2 tolerance for viewing sample data (CV2_CLOUD_VIEWING_tolerance, CV2_CLOUD_tolerance]\n",
    "CV2_CLOUD_VIEWING_tolerance = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine data availability at different tolerance levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cloud coverage list\n",
    "sent2_meta = np.load('sent2_metadata.npy').T\n",
    "cloud_coverage_list, rgb_mean, cv2_cloud_coverage_list = sent2_meta\n",
    "np_metadata(cloud_coverage_list, 'Cloud Coverage')\n",
    "\n",
    "# Plot the cloud coverage distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cloud_coverage_list, bins=20, kde=True, color='blue')\n",
    "plt.title('Cloud Coverage Distribution')\n",
    "plt.xlabel('Cloud Coverage (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the rgb mean distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(rgb_mean, bins=20, kde=True, color='blue')\n",
    "plt.title('RGB Mean Distribution')\n",
    "plt.xlabel('RGB Mean')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the cv2 cloud coverage distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(cv2_cloud_coverage_list, bins=20, kde=True, color='blue')\n",
    "plt.title('CV2 Cloud Coverage Distribution')\n",
    "plt.xlabel('Cloud Coverage (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "TABLE = np.zeros((11, 11), dtype=int)\n",
    "tmp_qa60_tolerance = 50\n",
    "\n",
    "def CV2_vs_RGB(cloud_tolerance, rgb_tolerance):\n",
    "        cnt = 0\n",
    "        for i in range(len(cv2_cloud_coverage_list)):\n",
    "            if cv2_cloud_coverage_list[i] <= cloud_tolerance and rgb_mean[i] >= rgb_tolerance * 0.1 and cloud_coverage_list[i] <= tmp_qa60_tolerance:\n",
    "                cnt += 1\n",
    "        return (cloud_tolerance, rgb_tolerance, cnt)\n",
    "\n",
    "num_processes = mp.cpu_count()\n",
    "print('Number of processes:', num_processes)\n",
    "pool = mp.Pool(processes=num_processes)\n",
    "args = [(cloud_tolerance, rgb_tolerance) for cloud_tolerance in range(0, 101, 10) for rgb_tolerance in range(0, 11, 1)]\n",
    "for outputs in tqdm(pool.starmap(CV2_vs_RGB, args), total=len(args)):\n",
    "    TABLE[outputs[0]//10][outputs[1]] = outputs[2]\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "# plot the table\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(TABLE, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('CV2 Cloud Coverage vs RGB Mean')\n",
    "plt.xlabel('RGB Tolerance (%)')\n",
    "plt.ylabel('CV2 Cloud Tolerance (%)')\n",
    "plt.xticks(ticks=np.arange(11), labels=[f'{i*0.1:.2f}' for i in range(0, 11, 1)])\n",
    "plt.yticks(ticks=np.arange(11), labels=[str(i) for i in range(0, 101, 10)])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save some valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(index):\n",
    "\n",
    "    # Load the image & normalize\n",
    "    image = get_image(index).squeeze()[1:4][::-1].transpose(1, 2, 0)\n",
    "    percentage = np.percentile(image, [5, 95])\n",
    "    image = np.clip(image, percentage[0], percentage[1])\n",
    "    image = (image - percentage[0]) / (percentage[1] - percentage[0])\n",
    "\n",
    "    # Load the QA60 band cloud mask\n",
    "    qa60 = get_image(index).squeeze()[4]\n",
    "    qa60 = np.stack(3*[qa60/2048.], axis=-1)\n",
    "\n",
    "    # Create cv2 cloud mask\n",
    "    cloud_mask = cv2_cloud_mask(image)\n",
    "    cv2_cloud_percentage = np.sum(cloud_mask/256) / cloud_mask.size * 100\n",
    "    if cv2_cloud_percentage <= CV2_CLOUD_VIEWING_tolerance:\n",
    "        return\n",
    "\n",
    "    # Create fig for plotting image and QA60 and cv2 cloud mask\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('RGB Image')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow((qa60), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('QA60 Mask')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cloud_mask, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('CV2 Mask')\n",
    "    plt.close(fig)\n",
    "    fig.savefig(f'pngs/sentinel2_valid_png_sample/{index}_{sent2_meta[0][index]:.2f}_{sent2_meta[1][index]:.3f}_{cv2_cloud_percentage:.3f}.png')\n",
    "\n",
    "num_processes = mp.cpu_count()\n",
    "print('Number of processes:', mp)\n",
    "pool = mp.Pool(processes=num_processes)\n",
    "args = [(i) for i in range(len(sent2_meta[0])) if (sent2_meta[0][i] <= QA60_tolerance and sent2_meta[1][i] >= BRIGHTNESS_tolerance and sent2_meta[2][i] <= CV2_CLOUD_tolerance)]\n",
    "print('Number of images:', len(args))\n",
    "args = random.sample(args, 1000)\n",
    "for _ in tqdm(pool.imap(save_image, args), total=len(args)):\n",
    "    pass\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save some invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(index):\n",
    "\n",
    "    # Load the image & normalize\n",
    "    image = get_image(index).squeeze()[1:4][::-1].transpose(1, 2, 0)\n",
    "    percentage = np.percentile(image, [5, 95])\n",
    "    image = np.clip(image, percentage[0], percentage[1])\n",
    "    image = (image - percentage[0]) / (percentage[1] - percentage[0])\n",
    "\n",
    "    # Load the QA60 band cloud mask\n",
    "    qa60 = get_image(index).squeeze()[4]\n",
    "    qa60 = np.stack(3*[qa60/2048.], axis=-1)\n",
    "\n",
    "    # Create cv2 cloud mask\n",
    "    cloud_mask = cv2_cloud_mask(image)\n",
    "    cv2_cloud_percentage = np.sum(cloud_mask/256) / cloud_mask.size * 100\n",
    "\n",
    "    # Create fig for plotting image and QA60 and cv2 cloud mask\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('RGB Image')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow((qa60), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('QA60 Mask')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cloud_mask, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('CV2 Mask')\n",
    "    plt.close(fig)\n",
    "    fig.savefig(f'pngs/sentinel2_invalid_png_sample/{index}_{sent2_meta[0][index]:.2f}_{sent2_meta[1][index]:.3f}_{cv2_cloud_percentage:.3f}.png')\n",
    "\n",
    "num_processes = mp.cpu_count()\n",
    "print('Number of processes:', mp)\n",
    "pool = mp.Pool(processes=num_processes)\n",
    "args = [i for i in range(len(sent2_meta[0])) if (sent2_meta[0][i] <= QA60_tolerance and sent2_meta[1][i] >= BRIGHTNESS_tolerance and sent2_meta[2][i] <= CV2_CLOUD_tolerance)]\n",
    "tmp_dict = {arg:None for arg in args}\n",
    "args = [(i) for i in range(len(sent2_meta[0])) if i not in tmp_dict]\n",
    "print('Number of images:', len(args))\n",
    "args = random.sample(args, 1000)\n",
    "for _ in tqdm(pool.imap(save_image, args), total=len(args)):\n",
    "    pass\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Valid Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [i for i in range(len(sent2_meta[0])) if (sent2_meta[0][i] <= QA60_tolerance and sent2_meta[1][i] >= BRIGHTNESS_tolerance and sent2_meta[2][i] <= CV2_CLOUD_tolerance)]\n",
    "args = np.array(args)\n",
    "np_metadata(args, 'Valid Image Indexes')\n",
    "np.save('sent2_valid_image_index.npy', args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Valid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images\n",
    "def get_image(idx):\n",
    "    Original_num_images = Original_sent2.variables['images'].shape[0]\n",
    "    Additional_num_images = Additional_sent2.variables['images'].shape[0]\n",
    "    if idx < Original_num_images:\n",
    "        return np.array(Original_sent2.variables['images'][idx])\n",
    "    else:\n",
    "        idx -= Original_num_images\n",
    "        img = np.array(Additional_sent2.variables['images'][idx])\n",
    "        img = img[[Additional_DATA_BANDS_DICT[band] for band in DATA_BANDS]]\n",
    "        return img\n",
    "    \n",
    "def normalize_image(image):\n",
    "    percentile = np.percentile(image, [5, 95])\n",
    "    image = np.clip(image, percentile[0], percentile[1])\n",
    "    image = (image - percentile[0]) / (percentile[1] - percentile[0])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Valid Images Indexes\n",
    "valid_image_indexes = np.load('sent2_valid_image_index.npy')\n",
    "np_metadata(valid_image_indexes, 'Valid Image Indexes')\n",
    "\n",
    "# Retrieve Metadata: COORDS, DATES, IMAGES\n",
    "if COORDS.shape[0] == 2: COORDS = COORDS.T\n",
    "if not COORDS.shape[0] == valid_image_indexes.shape[0]: COORDS = COORDS[valid_image_indexes]\n",
    "if not DATES.shape[0] == valid_image_indexes.shape[0]: DATES = DATES[valid_image_indexes]\n",
    "np_metadata(COORDS, 'Coordinates')\n",
    "np_metadata(DATES, 'Dates')\n",
    "\n",
    "DATES_NUM = [delta_from_date_date(date, date0='2018-12-13') for date in DATES]\n",
    "COORD_DATE_DICT = defaultdict(list)\n",
    "COORD_DATE_INDEX_DICT = {}\n",
    "for i in range(len(COORDS)):\n",
    "    COORD_DATE_DICT[tuple(COORDS[i])].append(DATES_NUM[i])\n",
    "    COORD_DATE_INDEX_DICT[(tuple(COORDS[i]), DATES_NUM[i])] = i\n",
    "diffs = []\n",
    "DIFFS_TO_PAIRS = defaultdict(list)\n",
    "for key in tqdm(COORD_DATE_DICT.keys(), desc='Creating Diffs Dictionary'):\n",
    "    dates = COORD_DATE_DICT[key]\n",
    "    dates = sorted(dates)\n",
    "    for i in range(1, len(dates)):\n",
    "        diffs.append(dates[i] - dates[i-1])\n",
    "        DIFFS_TO_PAIRS[dates[i] - dates[i-1]].append((COORD_DATE_INDEX_DICT[(key, dates[i-1])], COORD_DATE_INDEX_DICT[(key, dates[i])]))\n",
    "diffs = np.array(diffs)\n",
    "np_metadata(diffs, 'Diffs')\n",
    "\n",
    "# plot distribution of diffs\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(diffs, bins=20, kde=True, color='blue')\n",
    "plt.title('Distribution of Diffs')\n",
    "plt.xlabel('Diffs')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pair_plot(PAIR):\n",
    "    # Create a new figure\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # First subplot for the first image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    image1 = get_image(PAIR[0]).squeeze()[1:4][::-1].transpose(1, 2, 0)\n",
    "    plt.imshow(normalize_image(image1))\n",
    "    plt.axis('off')\n",
    "    plt.title('Image 1')\n",
    "    \n",
    "    # Second subplot for the second image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    image2 = get_image(PAIR[1]).squeeze()[1:4][::-1].transpose(1, 2, 0)\n",
    "    plt.imshow(normalize_image(image2))\n",
    "    plt.axis('off')\n",
    "    plt.title('Image 2')\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    output_dir = 'pngs/sentinel2_time_diff_2'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the figure\n",
    "    fig.savefig(f'{output_dir}/{PAIR[0]}_{PAIR[1]}.png')\n",
    "    \n",
    "    # Close the figure to prevent it from displaying\n",
    "    plt.close(fig)\n",
    "\n",
    "num_workers = mp.cpu_count()\n",
    "print('Number of workers:', num_workers)\n",
    "pool = mp.Pool(processes=num_workers)\n",
    "args = [PAIR for PAIR in DIFFS_TO_PAIRS[2]]\n",
    "for _ in tqdm(pool.imap(save_pair_plot, args), total=len(args), desc='Saving Pair Plots'):\n",
    "    pass\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental Prediction CSV Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = data_path\n",
    "DIR = sorted(os.listdir(data_directory))\n",
    "DIR = [file for file in DIR if ('.csv' in file)]\n",
    "\n",
    "env_pred_targets_file = 'prediction_targets.csv'\n",
    "env_pred_targets = pd.read_csv(os.path.join(data_directory, env_pred_targets_file))\n",
    "print(env_pred_targets.columns)\n",
    "\n",
    "# index column labeled Modality\n",
    "modalities = env_pred_targets['Modality']\n",
    "modalities = np.array(modalities)\n",
    "print('Modalities:', modalities)\n",
    "\n",
    "# Count each modality\n",
    "MODALITY = defaultdict(int)\n",
    "for modality in modalities:\n",
    "    MODALITY[modality.split('_')[0]] += 1\n",
    "print('Modality Count:', MODALITY)\n",
    "\n",
    "# index columb labeled Date\n",
    "dates = env_pred_targets['Date']\n",
    "dates = pd.to_datetime(dates, format='%Y_%m_%d')\n",
    "\n",
    "# Plot the date distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(dates, bins=20, kde=True, color='blue')\n",
    "plt.title('Date Distribution')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiearth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
