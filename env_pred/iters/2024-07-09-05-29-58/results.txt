Description: Reducing both learning rates by 10x, amp included
```
 Generator Model Params : 31434499
```
```
 Discriminator Model Params : 179137731
```
[  0, 0] : Loss_G 7.5265, Loss_D 0.4018
[  0, 1] : Loss_G 2.4080, Loss_D 0.0162
[  0, 2] : Loss_G 2.3176, Loss_D 0.0154
[  0, 3] : Loss_G 3.6412, Loss_D 0.0165
[  0, 4] : Loss_G 3.8721, Loss_D 0.0174
[  0, 5] : Loss_G 4.0278, Loss_D 0.0156
[  0, 6] : Loss_G 4.2315, Loss_D 0.0185
[  0, 7] : Loss_G 4.5819, Loss_D 0.0184
[  0, 8] : Loss_G 3.4202, Loss_D 0.0184
[  0, 9] : Loss_G 4.0499, Loss_D 0.0177
[  0, 10] : Loss_G 3.8561, Loss_D 0.0182
[  0, 11] : Loss_G 2.8402, Loss_D 0.0148
[  0, 12] : Loss_G 3.2348, Loss_D 0.0154
[  0, 13] : Loss_G 4.3795, Loss_D 0.0196
[  0, 14] : Loss_G 3.9545, Loss_D 0.0147
[  0, 15] : Loss_G 3.7546, Loss_D 0.0131
[  0, 16] : Loss_G 5.3497, Loss_D 0.0182
[  0, 17] : Loss_G 3.0871, Loss_D 0.0160
[  0, 18] : Loss_G 2.3180, Loss_D 0.0145
[  0, 19] : Loss_G 4.5200, Loss_D 0.0190
[  1, 0] : Loss_G 3.4805, Loss_D 0.0145
[  1, 1] : Loss_G 4.4984, Loss_D 0.0175
[  1, 2] : Loss_G 2.0661, Loss_D 0.0144
[  1, 3] : Loss_G 5.7291, Loss_D 0.0265
[  1, 4] : Loss_G 2.9647, Loss_D 0.0151
[  1, 5] : Loss_G 2.7655, Loss_D 0.0149
[  1, 6] : Loss_G 2.5973, Loss_D 0.0144
[  1, 7] : Loss_G 3.3823, Loss_D 0.0153
[  1, 8] : Loss_G 3.3635, Loss_D 0.0144
[  1, 9] : Loss_G 4.1928, Loss_D 0.0171
[  1, 10] : Loss_G 4.3066, Loss_D 0.0159
[  1, 11] : Loss_G 3.4495, Loss_D 0.0136
[  1, 12] : Loss_G 4.1072, Loss_D 0.0160
[  1, 13] : Loss_G 4.2761, Loss_D 0.0152
[  1, 14] : Loss_G 4.5588, Loss_D 0.0173
[  1, 15] : Loss_G 3.4594, Loss_D 0.0138
[  1, 16] : Loss_G 13.3773, Loss_D 0.2720
[  1, 17] : Loss_G 4.0402, Loss_D 0.0141
[  1, 18] : Loss_G 3.2072, Loss_D 0.0145
[  1, 19] : Loss_G 2.6269, Loss_D 0.0142
[  2, 0] : Loss_G 3.0368, Loss_D 0.0140
[  2, 1] : Loss_G 2.8465, Loss_D 0.0142
[  2, 2] : Loss_G 3.6969, Loss_D 0.0142
[  2, 3] : Loss_G 2.4752, Loss_D 0.0146
[  2, 4] : Loss_G 2.6472, Loss_D 0.0139
[  2, 5] : Loss_G 2.6703, Loss_D 0.0141
[  2, 6] : Loss_G 2.7548, Loss_D 0.0138
[  2, 7] : Loss_G 2.9159, Loss_D 0.0139
[  2, 8] : Loss_G 2.7026, Loss_D 0.0142
[  2, 9] : Loss_G 2.8209, Loss_D 0.0140
[  2, 10] : Loss_G 3.0629, Loss_D 0.0137
[  2, 11] : Loss_G 2.9764, Loss_D 0.0137
[  2, 12] : Loss_G 3.1147, Loss_D 0.0142
[  2, 13] : Loss_G 2.9159, Loss_D 0.0137
[  2, 14] : Loss_G 2.7397, Loss_D 0.0138
[  2, 15] : Loss_G 2.8460, Loss_D 0.0144
[  2, 16] : Loss_G 3.1821, Loss_D 0.0140
[  2, 17] : Loss_G 2.8710, Loss_D 0.0143
[  2, 18] : Loss_G 3.3958, Loss_D 0.0146
[  2, 19] : Loss_G 2.8475, Loss_D 0.0139
[  3, 0] : Loss_G 3.5680, Loss_D 0.0146
[  3, 1] : Loss_G 3.7326, Loss_D 0.0149
[  3, 2] : Loss_G 3.5659, Loss_D 0.0148
[  3, 3] : Loss_G 3.7173, Loss_D 0.0149
[  3, 4] : Loss_G 3.8183, Loss_D 0.0154
[  4, 0] : Loss_G 4.3037, Loss_D 0.0174
[  4, 1] : Loss_G 3.6637, Loss_D 0.0141
[  4, 2] : Loss_G 3.4340, Loss_D 0.0143
[  4, 3] : Loss_G 3.9867, Loss_D 0.0143
[  4, 4] : Loss_G 4.5967, Loss_D 0.0159
[  5, 0] : Loss_G 3.6793, Loss_D 0.0157
[  5, 1] : Loss_G 3.5799, Loss_D 0.0148
[  5, 2] : Loss_G 4.4049, Loss_D 0.0169
[  5, 3] : Loss_G 3.2785, Loss_D 0.0146
[  5, 4] : Loss_G 4.4123, Loss_D 0.0158
[  6, 0] : Loss_G 3.1806, Loss_D 0.0154
[  6, 1] : Loss_G 3.3496, Loss_D 0.0154
[  6, 2] : Loss_G 3.7150, Loss_D 0.0160
[  6, 3] : Loss_G 3.8746, Loss_D 0.0168
[  6, 4] : Loss_G 3.4438, Loss_D 0.0156
[  7, 0] : Loss_G 3.7165, Loss_D 0.0166
[  7, 1] : Loss_G 3.6860, Loss_D 0.0160
[  7, 2] : Loss_G 3.0838, Loss_D 0.0158
[  7, 3] : Loss_G 3.4093, Loss_D 0.0156
[  7, 4] : Loss_G 8.3501, Loss_D 0.2315
[  8, 0] : Loss_G 3.5373, Loss_D 0.0147
[  8, 1] : Loss_G 3.1677, Loss_D 0.0132
[  8, 2] : Loss_G 2.8723, Loss_D 0.0140
[  8, 3] : Loss_G 2.4313, Loss_D 0.0144
[  8, 4] : Loss_G 2.3907, Loss_D 0.0144
[  9, 0] : Loss_G 2.5295, Loss_D 0.0145
[  9, 1] : Loss_G 2.4104, Loss_D 0.0145
[  9, 2] : Loss_G 2.4715, Loss_D 0.0144
[  9, 3] : Loss_G 2.4361, Loss_D 0.0144
[  9, 4] : Loss_G 2.5132, Loss_D 0.0145
[ 10, 0] : Loss_G 2.4623, Loss_D 0.0146
[ 10, 1] : Loss_G 2.4392, Loss_D 0.0145
[ 10, 2] : Loss_G 2.5550, Loss_D 0.0161
[ 10, 3] : Loss_G 2.0630, Loss_D 0.0145
[ 10, 4] : Loss_G 2.1366, Loss_D 0.0146
[ 11, 0] : Loss_G 2.2803, Loss_D 0.0145
[ 11, 1] : Loss_G 2.3674, Loss_D 0.0148
[ 11, 2] : Loss_G 2.5526, Loss_D 0.0152
[ 11, 3] : Loss_G 2.7467, Loss_D 0.0156
[ 11, 4] : Loss_G 3.1321, Loss_D 0.0159
[ 12, 0] : Loss_G 3.1249, Loss_D 0.0161
[ 12, 1] : Loss_G 3.0239, Loss_D 0.0155
[ 12, 2] : Loss_G 3.6998, Loss_D 0.0168
[ 12, 3] : Loss_G 2.9124, Loss_D 0.0148
[ 12, 4] : Loss_G 3.5195, Loss_D 0.0164
[ 13, 0] : Loss_G 3.4040, Loss_D 0.0161
[ 13, 1] : Loss_G 3.4308, Loss_D 0.0158
[ 13, 2] : Loss_G 3.8893, Loss_D 0.0183
[ 13, 3] : Loss_G 3.4507, Loss_D 0.0154
[ 13, 4] : Loss_G 3.2754, Loss_D 0.0155
[ 14, 0] : Loss_G 3.3837, Loss_D 0.0156
[ 14, 1] : Loss_G 3.2971, Loss_D 0.0168
[ 14, 2] : Loss_G 3.1292, Loss_D 0.0152
[ 14, 3] : Loss_G 3.5854, Loss_D 0.0167
[ 14, 4] : Loss_G 2.9672, Loss_D 0.0150
[ 15, 0] : Loss_G 3.3866, Loss_D 0.0159
[ 15, 1] : Loss_G 5.1505, Loss_D 0.0551
[ 15, 2] : Loss_G 2.6250, Loss_D 0.0144
[ 15, 3] : Loss_G 2.5695, Loss_D 0.0144
[ 15, 4] : Loss_G 2.9623, Loss_D 0.0150
[ 16, 0] : Loss_G 3.2403, Loss_D 0.0153
[ 16, 1] : Loss_G 3.1878, Loss_D 0.0162
[ 16, 2] : Loss_G 3.0532, Loss_D 0.0150
[ 16, 3] : Loss_G 3.2332, Loss_D 0.0155
[ 16, 4] : Loss_G 3.8042, Loss_D 0.0193
[ 17, 0] : Loss_G 2.7139, Loss_D 0.0156
[ 17, 1] : Loss_G 2.9724, Loss_D 0.0164
[ 17, 2] : Loss_G 2.8153, Loss_D 0.0163
[ 17, 3] : Loss_G 2.8772, Loss_D 0.0157
[ 17, 4] : Loss_G 3.2468, Loss_D 0.0160
[ 18, 0] : Loss_G 3.3186, Loss_D 0.0156
[ 18, 1] : Loss_G 3.3167, Loss_D 0.0164
[ 18, 2] : Loss_G 3.1239, Loss_D 0.0166
[ 18, 3] : Loss_G 3.1063, Loss_D 0.0159
[ 18, 4] : Loss_G 2.8269, Loss_D 0.0158
[ 19, 0] : Loss_G 3.2141, Loss_D 0.0161
[ 19, 1] : Loss_G 3.1412, Loss_D 0.0158
[ 19, 2] : Loss_G 3.1777, Loss_D 0.0155
[ 19, 3] : Loss_G 3.2000, Loss_D 0.0158
[ 19, 4] : Loss_G 3.4527, Loss_D 0.0162
[ 20, 0] : Loss_G 2.9143, Loss_D 0.0150
[ 20, 1] : Loss_G 3.2374, Loss_D 0.0154
[ 20, 2] : Loss_G 3.2486, Loss_D 0.0154
[ 20, 3] : Loss_G 6.4454, Loss_D 0.1055
[ 20, 4] : Loss_G 3.1911, Loss_D 0.0132
[ 21, 0] : Loss_G 2.4537, Loss_D 0.0140
[ 21, 1] : Loss_G 2.2651, Loss_D 0.0143
[ 21, 2] : Loss_G 2.2641, Loss_D 0.0143
[ 21, 3] : Loss_G 2.3475, Loss_D 0.0143
[ 21, 4] : Loss_G 2.3532, Loss_D 0.0143
[ 22, 0] : Loss_G 2.3561, Loss_D 0.0142
[ 22, 1] : Loss_G 2.4405, Loss_D 0.0145
[ 22, 2] : Loss_G 2.4607, Loss_D 0.0144
[ 22, 3] : Loss_G 2.7746, Loss_D 0.0147
[ 22, 4] : Loss_G 3.2249, Loss_D 0.0152
[ 23, 0] : Loss_G 3.2394, Loss_D 0.0152
[ 23, 1] : Loss_G 3.1916, Loss_D 0.0154
[ 23, 2] : Loss_G 3.2341, Loss_D 0.0152
[ 23, 3] : Loss_G 3.3727, Loss_D 0.0154
[ 23, 4] : Loss_G 3.1637, Loss_D 0.0155
[ 24, 0] : Loss_G 3.1004, Loss_D 0.0149
[ 24, 1] : Loss_G 3.3533, Loss_D 0.0151
[ 24, 2] : Loss_G 3.2594, Loss_D 0.0149
[ 24, 3] : Loss_G 3.1539, Loss_D 0.0147
[ 24, 4] : Loss_G 3.3169, Loss_D 0.0153
[ 25, 0] : Loss_G 3.3704, Loss_D 0.0154
[ 25, 1] : Loss_G 3.2126, Loss_D 0.0145
[ 25, 2] : Loss_G 3.3581, Loss_D 0.0150
[ 25, 3] : Loss_G 3.3666, Loss_D 0.0148
[ 25, 4] : Loss_G 3.5080, Loss_D 0.0149
[ 26, 0] : Loss_G 3.4526, Loss_D 0.0151
[ 26, 1] : Loss_G 3.3673, Loss_D 0.0153
[ 26, 2] : Loss_G 2.8216, Loss_D 0.0142
[ 26, 3] : Loss_G 3.0984, Loss_D 0.0148
[ 26, 4] : Loss_G 3.1901, Loss_D 0.0146
[ 27, 0] : Loss_G 3.1730, Loss_D 0.0146
[ 27, 1] : Loss_G 5.3254, Loss_D 0.0816
[ 27, 2] : Loss_G 3.4733, Loss_D 0.0148
[ 27, 3] : Loss_G 2.6659, Loss_D 0.0141
[ 27, 4] : Loss_G 2.6509, Loss_D 0.0143
[ 28, 0] : Loss_G 2.8572, Loss_D 0.0146
[ 28, 1] : Loss_G 2.8239, Loss_D 0.0147
[ 28, 2] : Loss_G 2.8653, Loss_D 0.0147
[ 28, 3] : Loss_G 2.7992, Loss_D 0.0146
[ 28, 4] : Loss_G 2.8766, Loss_D 0.0150
[ 29, 0] : Loss_G 3.0961, Loss_D 0.0148
[ 29, 1] : Loss_G 2.9717, Loss_D 0.0149
[ 29, 2] : Loss_G 3.2039, Loss_D 0.0152
[ 29, 3] : Loss_G 3.0647, Loss_D 0.0148
[ 29, 4] : Loss_G 3.0836, Loss_D 0.0149
[ 30, 0] : Loss_G 3.1636, Loss_D 0.0147
[ 30, 1] : Loss_G 3.3202, Loss_D 0.0150
[ 30, 2] : Loss_G 3.2070, Loss_D 0.0148
[ 30, 3] : Loss_G 3.3322, Loss_D 0.0148
[ 30, 4] : Loss_G 3.2750, Loss_D 0.0148
[ 31, 0] : Loss_G 3.1542, Loss_D 0.0147
[ 31, 1] : Loss_G 3.1837, Loss_D 0.0146
[ 31, 2] : Loss_G 3.5386, Loss_D 0.0221
[ 31, 3] : Loss_G 2.4429, Loss_D 0.0152
[ 31, 4] : Loss_G 2.7725, Loss_D 0.0153
[ 32, 0] : Loss_G 2.6126, Loss_D 0.0148
[ 32, 1] : Loss_G 2.7238, Loss_D 0.0149
[ 32, 2] : Loss_G 2.8159, Loss_D 0.0152
[ 32, 3] : Loss_G 2.6705, Loss_D 0.0151
[ 32, 4] : Loss_G 2.6664, Loss_D 0.0148
[ 33, 0] : Loss_G 2.7590, Loss_D 0.0150
[ 33, 1] : Loss_G 5.6206, Loss_D 0.0761
[ 33, 2] : Loss_G 2.9093, Loss_D 0.0131
[ 33, 3] : Loss_G 2.7211, Loss_D 0.0134
[ 33, 4] : Loss_G 2.4070, Loss_D 0.0139
[ 34, 0] : Loss_G 2.1207, Loss_D 0.0141
[ 34, 1] : Loss_G 2.2415, Loss_D 0.0142
[ 34, 2] : Loss_G 2.2774, Loss_D 0.0143
[ 34, 3] : Loss_G 2.3833, Loss_D 0.0143
[ 34, 4] : Loss_G 2.3902, Loss_D 0.0144
[ 35, 0] : Loss_G 2.4913, Loss_D 0.0144
[ 35, 1] : Loss_G 2.9799, Loss_D 0.0148
[ 35, 2] : Loss_G 3.0074, Loss_D 0.0146
[ 35, 3] : Loss_G 3.2785, Loss_D 0.0151
[ 35, 4] : Loss_G 3.1467, Loss_D 0.0150
[ 36, 0] : Loss_G 3.0275, Loss_D 0.0147
[ 36, 1] : Loss_G 2.9835, Loss_D 0.0147
[ 36, 2] : Loss_G 2.8913, Loss_D 0.0147
[ 36, 3] : Loss_G 2.9510, Loss_D 0.0146
[ 36, 4] : Loss_G 3.1080, Loss_D 0.0148
[ 37, 0] : Loss_G 2.7553, Loss_D 0.0144
[ 37, 1] : Loss_G 2.9676, Loss_D 0.0147
[ 37, 2] : Loss_G 3.1488, Loss_D 0.0150
[ 37, 3] : Loss_G 2.9324, Loss_D 0.0147
[ 37, 4] : Loss_G 3.3187, Loss_D 0.0163
[ 38, 0] : Loss_G 2.6731, Loss_D 0.0183
[ 38, 1] : Loss_G 2.2098, Loss_D 0.0146
[ 38, 2] : Loss_G 2.5515, Loss_D 0.0146
[ 38, 3] : Loss_G 2.6078, Loss_D 0.0148
[ 38, 4] : Loss_G 2.8472, Loss_D 0.0153
[ 39, 0] : Loss_G 2.7010, Loss_D 0.0149
[ 39, 1] : Loss_G 2.6453, Loss_D 0.0147
[ 39, 2] : Loss_G 2.6034, Loss_D 0.0147
[ 39, 3] : Loss_G 2.9035, Loss_D 0.0148
[ 39, 4] : Loss_G 2.7768, Loss_D 0.0148
[ 40, 0] : Loss_G 4.9778, Loss_D 0.0911
[ 40, 1] : Loss_G 2.7565, Loss_D 0.0148
[ 40, 2] : Loss_G 2.4950, Loss_D 0.0145
[ 40, 3] : Loss_G 2.6544, Loss_D 0.0148
[ 40, 4] : Loss_G 3.2147, Loss_D 0.0153
[ 41, 0] : Loss_G 3.2246, Loss_D 0.0152
[ 41, 1] : Loss_G 3.3687, Loss_D 0.0158
[ 41, 2] : Loss_G 3.5157, Loss_D 0.0156
[ 41, 3] : Loss_G 3.5268, Loss_D 0.0153
[ 41, 4] : Loss_G 3.7482, Loss_D 0.0157
[ 42, 0] : Loss_G 3.3370, Loss_D 0.0153
[ 42, 1] : Loss_G 3.4832, Loss_D 0.0155
[ 42, 2] : Loss_G 3.2320, Loss_D 0.0150
[ 42, 3] : Loss_G 3.3784, Loss_D 0.0153
[ 42, 4] : Loss_G 3.0183, Loss_D 0.0148
[ 43, 0] : Loss_G 3.1863, Loss_D 0.0148
[ 43, 1] : Loss_G 3.2865, Loss_D 0.0150
[ 43, 2] : Loss_G 3.0793, Loss_D 0.0147
[ 43, 3] : Loss_G 3.2758, Loss_D 0.0148
[ 43, 4] : Loss_G 3.0072, Loss_D 0.0146
[ 44, 0] : Loss_G 3.0557, Loss_D 0.0146
[ 44, 1] : Loss_G 3.2028, Loss_D 0.0146
[ 44, 2] : Loss_G 3.3432, Loss_D 0.0149
[ 44, 3] : Loss_G 3.2106, Loss_D 0.0147
[ 44, 4] : Loss_G 3.0913, Loss_D 0.0146
[ 45, 0] : Loss_G 3.1461, Loss_D 0.0147
[ 45, 1] : Loss_G 3.0315, Loss_D 0.0144
[ 45, 2] : Loss_G 3.3689, Loss_D 0.0148
[ 45, 3] : Loss_G 3.3335, Loss_D 0.0146
[ 45, 4] : Loss_G 3.2316, Loss_D 0.0147
[ 46, 0] : Loss_G 3.1454, Loss_D 0.0145
[ 46, 1] : Loss_G 5.1686, Loss_D 0.0425
[ 46, 2] : Loss_G 1.8264, Loss_D 0.0147
[ 46, 3] : Loss_G 1.9113, Loss_D 0.0145
[ 46, 4] : Loss_G 2.0217, Loss_D 0.0144
[ 47, 0] : Loss_G 2.0305, Loss_D 0.0144
[ 47, 1] : Loss_G 2.1775, Loss_D 0.0144
[ 47, 2] : Loss_G 2.1549, Loss_D 0.0144
[ 47, 3] : Loss_G 2.2193, Loss_D 0.0145
[ 47, 4] : Loss_G 2.3461, Loss_D 0.0146
[ 48, 0] : Loss_G 2.3588, Loss_D 0.0145
[ 48, 1] : Loss_G 2.5166, Loss_D 0.0147
[ 48, 2] : Loss_G 2.5927, Loss_D 0.0146
[ 48, 3] : Loss_G 2.5255, Loss_D 0.0145
[ 48, 4] : Loss_G 2.6307, Loss_D 0.0147
[ 49, 0] : Loss_G 2.5693, Loss_D 0.0147
[ 49, 1] : Loss_G 2.6319, Loss_D 0.0148
[ 49, 2] : Loss_G 2.7283, Loss_D 0.0147
[ 49, 3] : Loss_G 2.6647, Loss_D 0.0148
[ 49, 4] : Loss_G 2.7494, Loss_D 0.0147
[ 50, 0] : Loss_G 2.9731, Loss_D 0.0148
[ 50, 1] : Loss_G 2.7424, Loss_D 0.0146
[ 50, 2] : Loss_G 2.7923, Loss_D 0.0146
[ 50, 3] : Loss_G 3.0286, Loss_D 0.0149
[ 50, 4] : Loss_G 2.9124, Loss_D 0.0146
[ 51, 0] : Loss_G 2.7888, Loss_D 0.0146
[ 51, 1] : Loss_G 2.9462, Loss_D 0.0149
[ 51, 2] : Loss_G 3.0166, Loss_D 0.0146
[ 51, 3] : Loss_G 2.8586, Loss_D 0.0147
[ 51, 4] : Loss_G 5.3679, Loss_D 0.0917
[ 52, 0] : Loss_G 2.7816, Loss_D 0.0143
[ 52, 1] : Loss_G 2.7237, Loss_D 0.0145
[ 52, 2] : Loss_G 2.8910, Loss_D 0.0146
[ 52, 3] : Loss_G 3.0393, Loss_D 0.0149
[ 52, 4] : Loss_G 2.8309, Loss_D 0.0146
[ 53, 0] : Loss_G 3.0500, Loss_D 0.0148
[ 53, 1] : Loss_G 2.7958, Loss_D 0.0144
[ 53, 2] : Loss_G 3.0408, Loss_D 0.0149
[ 53, 3] : Loss_G 2.9696, Loss_D 0.0145
[ 53, 4] : Loss_G 3.0029, Loss_D 0.0146
[ 54, 0] : Loss_G 3.0770, Loss_D 0.0147
[ 54, 1] : Loss_G 2.7042, Loss_D 0.0144
[ 54, 2] : Loss_G 2.9516, Loss_D 0.0146
[ 54, 3] : Loss_G 2.9312, Loss_D 0.0146
[ 54, 4] : Loss_G 2.9421, Loss_D 0.0147
[ 55, 0] : Loss_G 2.8933, Loss_D 0.0145
[ 55, 1] : Loss_G 2.9361, Loss_D 0.0145
[ 55, 2] : Loss_G 3.0277, Loss_D 0.0145
[ 55, 3] : Loss_G 2.9367, Loss_D 0.0145
[ 55, 4] : Loss_G 2.9351, Loss_D 0.0145
[ 56, 0] : Loss_G 2.9335, Loss_D 0.0144
[ 56, 1] : Loss_G 3.0310, Loss_D 0.0145
[ 56, 2] : Loss_G 2.8926, Loss_D 0.0143
[ 56, 3] : Loss_G 2.8939, Loss_D 0.0145
[ 56, 4] : Loss_G 2.9168, Loss_D 0.0142
[ 57, 0] : Loss_G 3.0232, Loss_D 0.0144
[ 57, 1] : Loss_G 2.9377, Loss_D 0.0145
[ 57, 2] : Loss_G 2.9964, Loss_D 0.0144
[ 57, 3] : Loss_G 2.9655, Loss_D 0.0143
[ 57, 4] : Loss_G 3.1464, Loss_D 0.0145
[ 58, 0] : Loss_G 2.9257, Loss_D 0.0144
[ 58, 1] : Loss_G 3.1528, Loss_D 0.0145
[ 58, 2] : Loss_G 2.9937, Loss_D 0.0144
[ 58, 3] : Loss_G 2.9445, Loss_D 0.0146
[ 58, 4] : Loss_G 2.8259, Loss_D 0.0145
[ 59, 0] : Loss_G 2.9449, Loss_D 0.0148
[ 59, 1] : Loss_G 6.6086, Loss_D 0.1743
[ 59, 2] : Loss_G 3.1108, Loss_D 0.0185
[ 59, 3] : Loss_G 2.5139, Loss_D 0.0143
[ 59, 4] : Loss_G 2.4461, Loss_D 0.0143
[ 60, 0] : Loss_G 2.2627, Loss_D 0.0144
[ 60, 1] : Loss_G 2.2469, Loss_D 0.0143
[ 60, 2] : Loss_G 2.3233, Loss_D 0.0142
[ 60, 3] : Loss_G 2.2112, Loss_D 0.0143
[ 60, 4] : Loss_G 2.2549, Loss_D 0.0144
[ 61, 0] : Loss_G 2.2647, Loss_D 0.0143
[ 61, 1] : Loss_G 2.2290, Loss_D 0.0144
[ 61, 2] : Loss_G 2.1411, Loss_D 0.0144
[ 61, 3] : Loss_G 2.1348, Loss_D 0.0145
[ 61, 4] : Loss_G 2.1601, Loss_D 0.0145
[ 62, 0] : Loss_G 2.1399, Loss_D 0.0145
[ 62, 1] : Loss_G 2.2670, Loss_D 0.0145
[ 62, 2] : Loss_G 2.4896, Loss_D 0.0147
[ 62, 3] : Loss_G 2.6955, Loss_D 0.0148
[ 62, 4] : Loss_G 2.8220, Loss_D 0.0150
[ 63, 0] : Loss_G 2.8818, Loss_D 0.0152
[ 63, 1] : Loss_G 2.7925, Loss_D 0.0148
[ 63, 2] : Loss_G 2.9475, Loss_D 0.0149
[ 63, 3] : Loss_G 2.9166, Loss_D 0.0149
[ 63, 4] : Loss_G 2.9850, Loss_D 0.0148
[ 64, 0] : Loss_G 3.1337, Loss_D 0.0147
[ 64, 1] : Loss_G 3.0817, Loss_D 0.0146
[ 64, 2] : Loss_G 2.8661, Loss_D 0.0146
[ 64, 3] : Loss_G 3.1533, Loss_D 0.0147
[ 64, 4] : Loss_G 2.8481, Loss_D 0.0144
[ 65, 0] : Loss_G 2.9354, Loss_D 0.0147
[ 65, 1] : Loss_G 3.0721, Loss_D 0.0146
[ 65, 2] : Loss_G 2.8475, Loss_D 0.0143
[ 65, 3] : Loss_G 3.0966, Loss_D 0.0146
[ 65, 4] : Loss_G 3.1246, Loss_D 0.0145
[ 66, 0] : Loss_G 2.9829, Loss_D 0.0143
[ 66, 1] : Loss_G 3.0624, Loss_D 0.0145
[ 66, 2] : Loss_G 2.8984, Loss_D 0.0144
[ 66, 3] : Loss_G 3.0389, Loss_D 0.0145
[ 66, 4] : Loss_G 2.9280, Loss_D 0.0144
[ 67, 0] : Loss_G 3.1888, Loss_D 0.0147
[ 67, 1] : Loss_G 2.9327, Loss_D 0.0143
[ 67, 2] : Loss_G 3.1075, Loss_D 0.0145
[ 67, 3] : Loss_G 3.0890, Loss_D 0.0146
[ 67, 4] : Loss_G 2.9001, Loss_D 0.0144
[ 68, 0] : Loss_G 2.9701, Loss_D 0.0146
[ 68, 1] : Loss_G 2.9933, Loss_D 0.0146
[ 68, 2] : Loss_G 2.9339, Loss_D 0.0145
[ 68, 3] : Loss_G 3.0443, Loss_D 0.0146
[ 68, 4] : Loss_G 5.5604, Loss_D 0.0671
[ 69, 0] : Loss_G 2.3126, Loss_D 0.0145
[ 69, 1] : Loss_G 2.1959, Loss_D 0.0145
[ 69, 2] : Loss_G 2.3281, Loss_D 0.0145
[ 69, 3] : Loss_G 2.5180, Loss_D 0.0147
[ 69, 4] : Loss_G 2.6964, Loss_D 0.0149
[ 70, 0] : Loss_G 2.6429, Loss_D 0.0148
[ 70, 1] : Loss_G 2.7918, Loss_D 0.0149
[ 70, 2] : Loss_G 2.8158, Loss_D 0.0148
[ 70, 3] : Loss_G 2.7521, Loss_D 0.0148
[ 70, 4] : Loss_G 2.6590, Loss_D 0.0145
[ 71, 0] : Loss_G 2.8128, Loss_D 0.0147
[ 71, 1] : Loss_G 2.7056, Loss_D 0.0146
[ 71, 2] : Loss_G 2.6578, Loss_D 0.0146
[ 71, 3] : Loss_G 2.8180, Loss_D 0.0145
[ 71, 4] : Loss_G 2.6949, Loss_D 0.0145
[ 72, 0] : Loss_G 2.6913, Loss_D 0.0144
[ 72, 1] : Loss_G 2.7900, Loss_D 0.0143
[ 72, 2] : Loss_G 2.8224, Loss_D 0.0145
[ 72, 3] : Loss_G 2.8705, Loss_D 0.0144
[ 72, 4] : Loss_G 2.8225, Loss_D 0.0144
[ 73, 0] : Loss_G 2.9884, Loss_D 0.0145
[ 73, 1] : Loss_G 2.7080, Loss_D 0.0142
[ 73, 2] : Loss_G 3.1043, Loss_D 0.0145
[ 73, 3] : Loss_G 2.8791, Loss_D 0.0141
[ 73, 4] : Loss_G 2.9238, Loss_D 0.0145
[ 74, 0] : Loss_G 3.0611, Loss_D 0.0145
[ 74, 1] : Loss_G 2.9085, Loss_D 0.0144
[ 74, 2] : Loss_G 2.8680, Loss_D 0.0145
[ 74, 3] : Loss_G 2.8994, Loss_D 0.0147
[ 74, 4] : Loss_G 2.8745, Loss_D 0.0143
[ 75, 0] : Loss_G 2.9789, Loss_D 0.0146
[ 75, 1] : Loss_G 2.9894, Loss_D 0.0147
[ 75, 2] : Loss_G 2.8697, Loss_D 0.0145
[ 75, 3] : Loss_G 2.9211, Loss_D 0.0147
[ 75, 4] : Loss_G 2.9804, Loss_D 0.0148
[ 76, 0] : Loss_G 2.9630, Loss_D 0.0145
[ 76, 1] : Loss_G 3.0397, Loss_D 0.0150
[ 76, 2] : Loss_G 2.7207, Loss_D 0.0142
[ 76, 3] : Loss_G 2.8021, Loss_D 0.0145
[ 76, 4] : Loss_G 3.0032, Loss_D 0.0147
[ 77, 0] : Loss_G 2.9146, Loss_D 0.0146
[ 77, 1] : Loss_G 2.9869, Loss_D 0.0147
[ 77, 2] : Loss_G 2.8621, Loss_D 0.0144
[ 77, 3] : Loss_G 6.4686, Loss_D 0.1310
[ 77, 4] : Loss_G 2.1976, Loss_D 0.0148
[ 78, 0] : Loss_G 2.1342, Loss_D 0.0142
[ 78, 1] : Loss_G 2.0247, Loss_D 0.0144
[ 78, 2] : Loss_G 2.0132, Loss_D 0.0144
[ 78, 3] : Loss_G 2.0799, Loss_D 0.0144
[ 78, 4] : Loss_G 2.0338, Loss_D 0.0145
[ 79, 0] : Loss_G 2.2176, Loss_D 0.0146
[ 79, 1] : Loss_G 2.8386, Loss_D 0.0158
[ 79, 2] : Loss_G 2.8225, Loss_D 0.0155
[ 79, 3] : Loss_G 2.8078, Loss_D 0.0158
[ 79, 4] : Loss_G 2.6944, Loss_D 0.0157
[ 80, 0] : Loss_G 2.8354, Loss_D 0.0154
[ 80, 1] : Loss_G 3.1634, Loss_D 0.0159
[ 80, 2] : Loss_G 2.8377, Loss_D 0.0152
[ 80, 3] : Loss_G 2.9840, Loss_D 0.0154
